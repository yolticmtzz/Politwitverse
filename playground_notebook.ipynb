{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysentimiento import create_analyzer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "# from pysentimiento.preprocessing import preprocess_tweet # using github preprocess instead\n",
    "import preprocessor as p\n",
    "import spacy\n",
    "import tweepy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "b_analyzer_sentiment = create_analyzer(task=\"sentiment\", lang=\"en\")\n",
    "b_analyzer_emotion = create_analyzer(task=\"emotion\", lang=\"en\")\n",
    "b_analyzer_hate_speech = create_analyzer(task=\"hate_speech\", lang=\"en\")\n",
    "v_analyzer_sentiment = SentimentIntensityAnalyzer()\n",
    "client = tweepy.Client(bearer_token='AAAAAAAAAAAAAAAAAAAAAGPIWwEAAAAANh02yZK%2Bg2Ga9OaIGmo%2FdcBKwI4%3DoBVTm4dbV9EsX06kTvtAz5XjSCK222TAxusnGUposUxAGoEFqg')\n",
    "p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.HASHTAG)\n",
    "TweetTokenizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realtime Tweet Sentiment Analyzer using BERTWEET engine and customized ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_sentiment_analyzer(text):\n",
    "    \n",
    "    temp = b_analyzer_sentiment.predict(text)\n",
    "    bert_sentiment_label = temp.output # output = neg, pos, neu label\n",
    "    bert_sentiment_score = temp.probas # probas = percentage score\n",
    "    NEG = round(bert_sentiment_score.get('POS'), 2)\n",
    "    POS = round(bert_sentiment_score.get('NEG'), 2)\n",
    "    NEU = round(bert_sentiment_score.get('NEU'), 2)\n",
    "    score_probability = max(NEG, POS, NEU)\n",
    "    bert_sentiment_list = [bert_sentiment_label, score_probability]\n",
    "    \n",
    "    return(bert_sentiment_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realtime Tweet Tokenizer using nltk's tweet tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_tokenization(clean_tweet_text):\n",
    "    \n",
    "    token = TweetTokenizer()\n",
    "    temp_tokens = token.tokenize(clean_tweet_text)  \n",
    "    nltk_tokens = []\n",
    "    for w in temp_tokens:\n",
    "         if w not in stop_words:\n",
    "             if len(w) > 2:\n",
    "                 nltk_tokens.append(w)\n",
    "                 \n",
    "    return(nltk_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @GlodeJo07: Me acabo de enterar que a Noroña le dio COVID…\n",
      "De corazón le deseo su pronta recuperación ante tan molesta y traumática expe…\n"
     ]
    }
   ],
   "source": [
    "client = tweepy.Client(bearer_token='AAAAAAAAAAAAAAAAAAAAAGPIWwEAAAAANh02yZK%2Bg2Ga9OaIGmo%2FdcBKwI4%3DoBVTm4dbV9EsX06kTvtAz5XjSCK222TAxusnGUposUxAGoEFqg')\n",
    "\n",
    "query = \"missouri schools -is:retweet lang:en\"\n",
    "for response in tweepy.Paginator(client.search_recent_tweets, \"covid\", tweet_fields=['author_id'], user_fields=['created_at', 'name'],\n",
    "                              max_results=10).flatten(limit=1):\n",
    "    print(response)\n",
    "# response = client.search_recent_tweets(query=query,tweet_fields=['attachments','author_id','context_annotations','conversation_id','created_at','entities','geo,id','in_reply_to_user_id','lang','possibly_sensitive','public_metrics','referenced_tweets','reply_settings','source','text','withheld'],user_fields=['created_at','description','entities,id','location','name','pinned_tweet_id','profile_image_url','protected,public_metrics','url','username','verified','withheld'],expansions=['attachments.poll_ids','attachments.media_keys','author_id','geo.place_id','in_reply_to_user_id','referenced_tweets.id','entities.mentions.username','referenced_tweets.id.autho(r_id'],media_fields=['duration_ms','height','media_key', 'preview_image_url','promoted_metrics','public_metrics','type,url'],place_fields=['contained_within,country','country_code','full_name','geo,id','name','place_type'],poll_fields=['duration_minutes','end_datetime','id','options','voting_status'],max_results=10)  \n",
    "# for tweet in response.data: \n",
    "#     # print(\"orginal tweet: \" +tweet.text)\n",
    "#     print('----------------------------------------------------------------------------------------')\n",
    "#     clean_tweet_text = p.clean(tweet.text)\n",
    "#     clean_tweet_text = clean_tweet_text.replace(\"&amp\", \"\")  \n",
    "#     tweet_sentiment = tweet_sentiment_analyzer(tweet.text)\n",
    "#     nltk_tokens = tweet_tokenization(clean_tweet_text) \n",
    "#     # print(tweet.text)\n",
    "#     # print(clean_tweet_text)\n",
    "#     # print(nltk_tokens)\n",
    "#     # print(tweet_sentiment)\n",
    "#     # print(tweet.data)\n",
    "#     print(tweet.context_annotations)\n",
    "#     print('------------------------------------------------------------------------------------------')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33db5c7e3bb784b844c2c176e5e511469c44d8edbdec04c9eaa139fbb1e863e8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
